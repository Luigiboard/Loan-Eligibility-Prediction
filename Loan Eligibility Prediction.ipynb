{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Import Relevant Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import relevant modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and read the data\n",
    "train = pd.read_csv('Loan Eligibility Prediction Datasets/train_ctrUa4K.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('Loan Eligibility Prediction Datasets/test_lAUu6dG.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the original dataset\n",
    "\n",
    "train_original = train.copy()\n",
    "test_original = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first the target variable\n",
    "train.Loan_Status.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Loan_Status.value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then categorical features\n",
    "\n",
    "cat_feat = ['Gender','Married','Self_Employed','Credit_History','Loan_Status']\n",
    "\n",
    "for col in cat_feat:\n",
    "    counts = train[col].value_counts(normalize=True).sort_index()\n",
    "    fig = plt.figure(figsize=(9,6))\n",
    "    ax = fig.gca()\n",
    "    counts.plot.bar(ax=ax,color='steelblue')\n",
    "    ax.set_title(col + ' '+ 'counts')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after ordinal features\n",
    "\n",
    "ord_feat=['Dependents','Education','Property_Area']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ord_feat:\n",
    "    counts = train[col].value_counts(normalize=True).sort_index()\n",
    "    fig = plt.figure(figsize=(9,6))\n",
    "    ax = fig.gca()\n",
    "    counts.plot.bar(ax=ax,color='steelblue')\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel(col+' '+'counts')\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally numerical features\n",
    "\n",
    "num_feat = ['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term']\n",
    "\n",
    "\n",
    "for col in num_feat:\n",
    "    feature = train[col]\n",
    "    fig,ax = plt.subplots(2,1,figsize=(9,6))\n",
    "    ax[0].hist(feature,bins=100)\n",
    "    sns.boxplot(feature,x=col,ax=ax[1])\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Bivariate Analysis of Features Against the Label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender=pd.crosstab(train['Gender'],train['Loan_Status'])\n",
    "Gender.div(Gender.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True,figsize=(4,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_feat:\n",
    "    counts = train[col].value_counts(normalize=True).sort_index()\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    counts.plot.bar(x = col , y = train.Loan_Status, ax = ax)\n",
    "    ax.set_title('Label by ' + col)\n",
    "    ax.set_ylabel(\"Loan Status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender = pd.crosstab(train.Gender,train.Loan_Status)\n",
    "Gender.div(Gender.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True,figsize=(4,4))\n",
    "plt.show()\n",
    "\n",
    "Married=pd.crosstab(train['Married'],train['Loan_Status'])\n",
    "Married.div(Married.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True,figsize=(4,4))\n",
    "plt.show()\n",
    "\n",
    "Self_Employed = pd.crosstab(train.Self_Employed,train.Loan_Status)\n",
    "Self_Employed.div(Self_Employed.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True,figsize=(4,4))\n",
    "plt.show()\n",
    "\n",
    "Credit_History = pd.crosstab(train.Credit_History,train.Loan_Status)\n",
    "Credit_History.div(Credit_History.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True,figsize=(4,4))\n",
    "plt.show()\n",
    "\n",
    "'Dependents','Education','Property_Area'\n",
    "\n",
    "Dependents = pd.crosstab(train.Dependents,train.Loan_Status)\n",
    "Dependents.div(Dependents.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True,figsize=(4,4))\n",
    "plt.show()\n",
    "\n",
    "Education = pd.crosstab(train.Education,train.Loan_Status)\n",
    "Education.div(Education.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True,figsize=(4,4))\n",
    "plt.show()\n",
    "\n",
    "Property_Area = pd.crosstab(train.Property_Area,train.Loan_Status)\n",
    "Property_Area.div(Property_Area.sum(1).astype(float), axis=0).plot(kind='bar',stacked=True,figsize=(4,4))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('Loan_Status')['ApplicantIncome'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.ApplicantIncome.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0,2500,4000,6000,81000]\n",
    "groups = ['low','average','high','very_high']\n",
    "\n",
    "train['Income_Bin'] = pd.cut(x=train['ApplicantIncome'],bins=bins,labels=groups)\n",
    "Income_Bin = pd.crosstab(train.Income_Bin,train.Loan_Status)\n",
    "Income_Bin.div(Income_Bin.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True)\n",
    "plt.xlabel('Applicant Income')\n",
    "plt.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.CoapplicantIncome.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0,1000,3000,42000]\n",
    "groups = ['low','average','high',]\n",
    "\n",
    "train['Co_Income_Bin'] = pd.cut(x=train['CoapplicantIncome'],bins=bins,labels=groups)\n",
    "Co_Income_Bin = pd.crosstab(train.Co_Income_Bin,train.Loan_Status)\n",
    "Co_Income_Bin.div(Co_Income_Bin.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True)\n",
    "plt.xlabel('CoApplicant Income')\n",
    "plt.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0,2500,4000,6000,81000]\n",
    "groups = ['low','average','high','very_high']\n",
    "train['Total_Income'] = train['ApplicantIncome'] + train['CoapplicantIncome']\n",
    "train['Total_Income_Bin'] = pd.cut(x=train['Total_Income'],bins=bins,labels=groups)\n",
    "Total_Income_Bin = pd.crosstab(train.Total_Income_Bin,train.Loan_Status)\n",
    "Total_Income_Bin.div(Total_Income_Bin.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True)\n",
    "plt.xlabel('Total Applicant Income')\n",
    "plt.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.LoanAmount.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0,100,200,700]\n",
    "groups = ['low','average','high']\n",
    "\n",
    "train['Loan_Bin'] = pd.cut(x=train['LoanAmount'],bins=bins,labels=groups)\n",
    "Loan_Bin = pd.crosstab(train.Loan_Bin,train.Loan_Status)\n",
    "Loan_Bin.div(Loan_Bin.sum(1).astype(float),axis=0).plot(kind='bar',stacked=True)\n",
    "plt.xlabel('Loan Bin')\n",
    "plt.ylabel('Percentage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop(['Income_Bin', 'Income_Bin', 'Co_Income_Bin', 'Total_Income',\n",
    "       'Total_Income_Bin', 'Loan_Bin'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Dependents.replace('3+',3,inplace=True)\n",
    "test.Dependents.replace('3+',3,inplace=True)\n",
    "train.Loan_Status.replace('Y',1,inplace=True)\n",
    "train.Loan_Status.replace('N',0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train.corr(),cmap='BuPu',annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Data Cleaning And Handling of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for missing values \n",
    "\n",
    "train[train.columns[train.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_cat_feat = ['Gender','Married','Dependents','Self_Employed','Credit_History']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the categorical missing values with the mode\n",
    "\n",
    "for col in miss_cat_feat:\n",
    "    train[col].fillna(train[col].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in miss_cat_feat:\n",
    "    test[col].fillna(test[col].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.columns[train.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[test.columns[test.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Loan_Amount_Term'].fillna(train.Loan_Amount_Term.mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Loan_Amount_Term'].fillna(test.Loan_Amount_Term.mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill with median\n",
    "\n",
    "train.LoanAmount.fillna(train.LoanAmount.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.LoanAmount.fillna(test.LoanAmount.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm no missing values \n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization,in this case boxplot, to show extent of outliers\n",
    "\n",
    "plt.boxplot(train.LoanAmount,vert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize using log transformation\n",
    "train['LoanAmountLog'] = np.log(train.LoanAmount)\n",
    "\n",
    "test['LoanAmountLog'] = np.log(test.LoanAmount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.LoanAmountLog.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('Loan_ID',axis=1)\n",
    "test = test.drop('Loan_ID',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covert features to dummy variables\n",
    "\n",
    "train = pd.get_dummies(train)\n",
    "test = pd.get_dummies(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate features from target variable\n",
    "\n",
    "X = train.drop('Loan_Status',1)\n",
    "y = train.Loan_Status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and validation sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilise appropiate algorithms and estimators in this case LogisticRegression as a starting point \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression(C=1/0.01,solver='liblinear').fit(X_train,y_train)\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "print('Accuracy_score:',accuracy_score(y_val,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check performance using various metrics. Classification report provides some of the metric measures together\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_val,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "pred_test = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submit first model\n",
    "submission = pd.read_csv('C:/Users/Admin/Documents/Competition Files/Loan Eligibility Prediction Datasets/sample_submission_49d68Cx.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[submission['Loan_Status']=='N']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.Loan_Status = pred_test\n",
    "submission.Loan_ID = test_original.Loan_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.Loan_Status.replace(0,'N',inplace=True)\n",
    "submission.Loan_Status.replace(1,'Y',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Metrics Measurement And Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr,tpr,thresholds = roc_curve(y_val,y_scores[:,1])\n",
    "\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(y_val,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Model 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Define preprocessing for numeric columns \n",
    "numeric_features = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
    "       'Loan_Amount_Term', 'Credit_History','LoanAmountLog']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define preprocessing for categorical features\n",
    "categorical_features = ['Gender_Female', 'Gender_Male', 'Married_No', 'Married_Yes',\n",
    "       'Dependents_3', 'Dependents_0', 'Dependents_1', 'Dependents_2',\n",
    "       'Education_Graduate', 'Education_Not Graduate', 'Self_Employed_No',\n",
    "       'Self_Employed_Yes', 'Property_Area_Rural', 'Property_Area_Semiurban',\n",
    "       'Property_Area_Urban']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('logregressor', LogisticRegression(C=1/0.01, solver=\"liblinear\"))])\n",
    "\n",
    "\n",
    "# fit the pipeline to train a logistic regression model on the training set\n",
    "model = pipeline.fit(X_train, (y_train))\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,roc_curve,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Performance And Scores \n",
    "\n",
    "predictions = model.predict(X_val)\n",
    "y_scores = model.predict_proba(X_val)\n",
    "cm = confusion_matrix(y_val, predictions)\n",
    "print ('Confusion Matrix:\\n',cm, '\\n')\n",
    "print('Accuracy:', accuracy_score(y_val, predictions))\n",
    "print(\"Overall Precision:\",precision_score(y_val, predictions))\n",
    "print(\"Overall Recall:\",recall_score(y_val, predictions))\n",
    "auc = roc_auc_score(y_val,y_scores[:,1])\n",
    "print('\\nAUC: ' + str(auc))\n",
    "\n",
    "# calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_scores[:,1])\n",
    "\n",
    "# plot ROC curve\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit Model 2\n",
    "pd.DataFrame(submission,columns=['Loan_ID','Loan_Status']).to_csv('/Loan Eligibility Prediction Datasets/submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
